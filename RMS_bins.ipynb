{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81cbdb4",
   "metadata": {},
   "source": [
    "**RMS_bins.ipynb**\n",
    "\n",
    "This notebook generates the look-up table \"CINDI_RMS_LUT.csv\".\n",
    "The look-up table contains the RMS thresholds, defined by the 95 percentiles for each Pandora ID, dataproduct, reference type and elevation angle. The RMS thresholds are later used to filter the data in the defined bins.\n",
    "\n",
    "In this notebook, the unfiltered CINDI3 data are binned in 6 (or 10) bins of SZA for all routines during elevation scan phase (or during twilight phase (routines 'IW')). The 95 percentile RMS is calculated for each bin and stored in a pandas.DataFrame LUT in the variable \"rms\" together with the respective bin edges \"sza\". The bin edges are split in two lists of the lower edges \"sza_left\" and the upper edges \"sza_right\" for better readability in the produced .csv file.\n",
    "\n",
    "How to generate / use this script:\n",
    "1) Run \"main_makeCompData.py\" for all Pandora IDs, dates, dataproducts and reference types. SZA binning should be disabled (last row in \"processCompDataInput.txt\": *SZA binning for RMS filtering (...) -> **NO***). Make to enable the conversion to CINDI3 blind comparison format. Move the files to folders named as the dates (\"YYYYMMDD\").\n",
    "2) Specifiy the path to the folder containing all date folders in the next cell, and run all following cells of this notebook. Store the variable LUT in \".csv\" format (last cell).\n",
    "3) If it's not in the correct path, move \"CINDI_RMS_LUT.csv\" to the root path of \"main_makeCompData.py\". Run \"main_makeCompData.py this time with SZA binning (last row in \"processCompDataInput.txt\" set to *SZA binning for RMS filtering (...) -> **FROMFILE***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948cc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xa\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# navigate to folder that contains subfolders of dates '20240527', '20240528', ..., '20240621'\n",
    "# subfolders of dates contain CINDI-3 submission files\n",
    "path='C:/Users/Stefanie Morhenn/PycharmProjects/Blick/src/CINDI3/v1.6 (no RMS filtering)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "dates = os.listdir()\n",
    "data = xa.Dataset(\n",
    "    data_vars=dict(\n",
    "        RMS=(['PAN_ID','DATE','REF','DATAPRODUCT','VEA','TIME_INDEX'],np.zeros((3,len(dates),3,12,32,1000))*np.nan),\n",
    "        SZA=(['PAN_ID','DATE','REF','DATAPRODUCT','VEA','TIME_INDEX'],np.zeros((3,len(dates),3,12,32,1000))*np.nan),\n",
    "        RTN=(['PAN_ID','DATE','REF','DATAPRODUCT','VEA','TIME_INDEX'],np.empty((3,len(dates),3,12,32,1000),dtype='<U2')),\n",
    "        ),\n",
    "    coords=dict(PAN_ID=('PAN_ID',np.array(['34','35','36'])), \n",
    "                DATE=('DATE', np.array(dates)), \n",
    "                REF=('REF',np.array(['DAILYREF', 'SEQREF','FIXREF'])), \n",
    "                DATAPRODUCT=('DATAPRODUCT',np.array(['O4VIS','O4UV','O3VIS','O3UV','NO2VIS-SMALL','NO2VIS','NO2UV','HONO','HCHO-WIDE','HCHO','CHOCHO','BRO'])), \n",
    "                VEA=('VEA', np.array([-5.,-4.,-3.,-2.,-1.8,-1.6,-1.2,-1.1,-1.,-0.8,-0.6,-0.4,-0.2,0.,0.2,0.4,0.6,0.8,1.,1.2,1.4,1.6,1.8,2.,3.,4.,5.,6.,8.,15.,30.,90.])), \n",
    "                TIME=('TIME_INDEX', np.arange((1000))),\n",
    "    )\n",
    ")\n",
    "\n",
    "for date in dates:\n",
    "    os.chdir(date)\n",
    "    for file in os.listdir():\n",
    "        p_id = file.split('_')[2]\n",
    "        ref = file.split('_')[4]\n",
    "        dataproduct = file.split('_')[3]\n",
    "        with open(file,'r') as f:\n",
    "            iw_finished=False\n",
    "            sza = []\n",
    "            vea = []\n",
    "            rms = []\n",
    "            rtn = []\n",
    "            lines = f.readlines()\n",
    "            for iline, line in enumerate(lines):\n",
    "                print()\n",
    "                if '% ' in line[:2]:\n",
    "                    # index of rms column in file\n",
    "                    if 'Fit RMS' in line[2:] and 'Col' in line[2:]:\n",
    "                        # index is written number behind '% Col ' - 1\n",
    "                        i_rms = int(line.split('Col ')[-1].split(':')[0]) - 1\n",
    "                        print(i_rms)\n",
    "                else:\n",
    "                    linelist = line.split(' ')\n",
    "                    # extract time for distinction between twilight and non-twilight measurements\n",
    "                    time = float(linelist[1])\n",
    "                    sza.append(float(linelist[3]))\n",
    "                    vea.append(float(linelist[5]))\n",
    "                    rms.append(float(linelist[i_rms]))\n",
    "                    # set flag prev_elev_scan_complete to False if a new elevation scan begins\n",
    "                    if vea[-1] == -2 and iw_finished:\n",
    "                        prev_elev_scan_complete = False\n",
    "                    if vea[-1] == 90 and iw_finished:\n",
    "                        prev_elev_scan_complete = True\n",
    "                    # make distinction between twilight measurements ('IW') and non-twilight measurements ('IX'), based on timestamp and vea in CINDI-3 file\n",
    "                    # first: early twilight measurements\n",
    "                    if vea[-1] != 90 and not iw_finished:\n",
    "                        iw_finished=True\n",
    "                        i_first_elev_scan = copy(iline)\n",
    "                    # then: late twilight measurements\n",
    "                    if time >= 19+1/6 and iw_finished:\n",
    "                        if prev_elev_scan_complete:\n",
    "                            iw_finished=False\n",
    "                        else:\n",
    "                            print(p_id)\n",
    "                            print(ref)\n",
    "                            print(dataproduct)\n",
    "                            print(date)\n",
    "                            print('Please check if VEA=%s, timestamp=%s is associated to last measurement of elevation scan or to IW routine. We will assume it belongs to IW.' % (vea[-1],time))\n",
    "                            iw_finished=False\n",
    "                    rtn.append('IX' if iw_finished else 'IW')\n",
    "            vea_arr = np.array(vea)\n",
    "            rms_arr = np.array(rms)\n",
    "            sza_arr = np.array(sza)\n",
    "            rtn_arr = np.array(rtn)\n",
    "            for angle in np.unique(vea_arr):\n",
    "                indices = np.where(vea_arr==angle)[0]\n",
    "                data.RMS.loc[dict(PAN_ID=p_id,DATE=date,REF=ref,DATAPRODUCT=dataproduct,VEA=angle,TIME_INDEX=slice(0,len(indices)))] = rms_arr[indices]\n",
    "                data.SZA.loc[dict(PAN_ID=p_id,DATE=date,REF=ref,DATAPRODUCT=dataproduct,VEA=angle,TIME_INDEX=slice(0,len(indices)))] = sza_arr[indices]\n",
    "                data.RTN.loc[dict(PAN_ID=p_id,DATE=date,REF=ref,DATAPRODUCT=dataproduct,VEA=angle,TIME_INDEX=slice(0,len(indices)))] = rtn_arr[indices]\n",
    "\n",
    "    os.chdir('..')\n",
    "\n",
    "# find maximum TIME_INDEX to shorten array \n",
    "imax=0\n",
    "for ip in data.PAN_ID.values:\n",
    "    for id in data.DATE.values:\n",
    "        for ir in data.REF.values:\n",
    "            for idp in data.DATAPRODUCT.values:\n",
    "                for ivea in data.VEA.values:\n",
    "                    rms_slice = data.sel(PAN_ID=ip,DATE=id,REF=ir,DATAPRODUCT=idp,VEA=ivea).RMS.values\n",
    "                    n_valid = np.count_nonzero(~np.isnan(rms_slice))#len(rms_slice[~np.isnan(data.sel(PAN_ID=ip,DATE=id,REF=ir,DATAPRODUCT=idp,VEA=ivea).RMS.data)])\n",
    "                    if n_valid>imax:\n",
    "                        imax=n_valid\n",
    "\n",
    "data = data.isel(TIME_INDEX=slice(0,imax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning for each instrument, dataproduct, reference, VEA\n",
    "LUT=pd.DataFrame(list(itertools.product(\n",
    "    data.PAN_ID.data, data.DATAPRODUCT.data, data.REF.data, data.VEA.data, ['IW','IX']\n",
    ")),\n",
    "columns=['pan_id','dataproduct','ref','vea','rtn'])\n",
    "LUT['rms'] = [[] for _ in range(len(LUT))]\n",
    "LUT['sza'] = [[] for _ in range(len(LUT))]\n",
    "LUT_rows = []\n",
    "for index, row in LUT.iterrows():\n",
    "    data_sub = data.sel(PAN_ID=row.pan_id,DATAPRODUCT=row.dataproduct,REF=row.ref)\n",
    "    data_sub = data_sub.where((data_sub.VEA==row.vea) & (data_sub.RTN==row.rtn),drop=True)\n",
    "\n",
    "    if data_sub.RTN.shape == (0,0,0):\n",
    "        continue\n",
    "    if row.rtn == 'IW':\n",
    "        stepsize=10\n",
    "    else:\n",
    "        stepsize=6\n",
    "    bin_edges = np.linspace(np.nanmax(data_sub.SZA)+1e-3,np.nanmin(data_sub.SZA),stepsize+1)\n",
    "    data_sub_binned = data_sub.groupby_bins('SZA',bins=bin_edges[::-1],right=False)\n",
    "    for label, group in data_sub_binned:\n",
    "        threshold=group['RMS'].quantile(0.95)\n",
    "        LUT.at[index,'rms'].append(threshold.data.item())\n",
    "        LUT.at[index,'sza'].append(label)\n",
    "\n",
    "LUT['pan_id']=LUT['pan_id'].replace('34','118')\n",
    "LUT['pan_id']=LUT['pan_id'].replace('35','81')\n",
    "LUT['pan_id']=LUT['pan_id'].replace('36','83')\n",
    "LUT['ref']=LUT['ref'].replace('DAILYREF','Ref')\n",
    "LUT['ref']=LUT['ref'].replace('FIXREF','RefFix')\n",
    "LUT['ref']=LUT['ref'].replace('SEQREF','MeasLow')\n",
    "\n",
    "list_sza_left = []\n",
    "list_sza_right = []\n",
    "for index in LUT.index:\n",
    "    sza_left=[i.left for i in LUT.loc[index]['sza']]\n",
    "    sza_right=[i.right for i in LUT.loc[index]['sza']]\n",
    "    list_sza_left.append(sza_left)\n",
    "    list_sza_right.append(sza_right)\n",
    "LUT['sza_left'] = list_sza_left\n",
    "LUT['sza_right'] = list_sza_right"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
